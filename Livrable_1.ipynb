{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Livrable 1<br />-<br /> Projet Ademe</center>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La prise de conscience mondiale de la nécessité de réduire la consommation d'énergie et les émissions de gaz à effet de serre s'est accrue depuis les années 90, avec des engagements tels que le protocole de Kyoto et les objectifs ambitieux qui en découlent. Les efforts se concentrent sur le changement de comportement, en mettant l'accent sur l'économie et le recyclage des matériaux, l'amélioration des transports et l'accroissement de l'efficacité énergétique des bâtiments. Cependant, il reste des défis à relever pour imposer le changement aux entreprises et aux particuliers."
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1611732956.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    Global awareness of the need to reduce energy consumption and greenhouse gas emissions has grown since the 90s, with commitments such as the Kyoto Protocol and subsequent ambitious targets. Efforts are focused on changing behavior, emphasizing saving and recycling materials, improving transportation, and enhancing energy efficiency in buildings. However, challenges remain in enforcing change among companies and individuals.\u001B[0m\n\u001B[1;37m           ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Projet de Mobilité Multimodale Intelligente pour la Gestion de Tournées de Livraison\n",
    "\n",
    "### Description\n",
    "\n",
    "L'ADEME (Agence de l'Environnement et de la Maîtrise de l'Énergie) a récemment lancé un appel à manifestation d'intérêt visant à promouvoir la réalisation de démonstrateurs et d'expérimentations de nouvelles solutions de mobilité adaptées aux différents types de territoires, tant pour les personnes que pour les marchandises.\n",
    "\n",
    "CesiCDP, est déjà bien implantée dans le domaine de la Mobilité Multimodale Intelligente. Avec l'aide de nombreux partenaires, nous avons réalisé plusieurs études sur ce sujet. Les nouvelles technologies de transport, plus économiques et respectueuses de l'environnement, posent néanmoins de nouveaux défis, notamment en termes d'optimisation de la gestion des ressources. La logistique du transport représente un enjeu majeur pour l'avenir, car ses applications sont nombreuses (distribution du courrier, livraison de produits, traitement du réseau routier, ramassage des ordures) et leur impact sur l'environnement peut être significatif.\n",
    "\n",
    "L'équipe de CesiCDP, composée de 4 personnes, chargée de répondre à l'appel de l'ADEME. L'objectif est de remporter de nouveaux marchés bénéficiant de financements attractifs afin de poursuivre le développement de notre activité.\n",
    "\n",
    "CesiCDP a décidé de se concentrer sur l'étude de la gestion des tournées de livraison. Le problème algorithmique consiste à calculer une tournée sur un réseau routier reliant un sous-ensemble de villes, tout en minimisant la durée totale de la tournée, de sorte à revenir au point de départ.\n",
    "\n",
    "L'idée est de proposer une méthode basée sur la Recherche Opérationnelle pour générer une tournée de livraison répondant à ce problème.\n",
    "\n",
    "Le périmètre du projet doit encore être précisé. Nous avons décrit une version de base du problème, mais afin de le rendre plus réaliste et d'attirer toute l'attention de l'ADEME,il nous faudra ajouter une ou des contraintes supplémentaires. Cela rendra le problème plus complexe à résoudre.\n",
    "\n",
    "### Version de base\n",
    "\n",
    "- Choix d'un modèle et d'un code en Python capable de résoudre des instances de taille importante (plusieurs milliers de villes).\n",
    "- Étude statistique du comportement expérimental de l'algorithme.\n",
    "\n",
    "### Contraintes supplémentaires\n",
    "\n",
    "Voici une liste non exhaustive de contraintes qui pourraient être intégrées au périmètre de notre étude.\n",
    "\n",
    "Certaines contraintes disposent également de versions avancées.\n",
    "\n",
    "- Fenêtre de temps de livraison pour chaque objet\n",
    "    - Interdiction de livrer hors de la fenêtre\n",
    "    - Possibilité d'attendre sur place l'ouverture de la fenêtre temporelle\n",
    "\n",
    "- Disponibilité simultanée de k camions pour effectuer les livraisons\n",
    "    - Capacité des camions (2 ou 3 dimensions) et encombrement des objets\n",
    "    - Certains objets ne peuvent être livrés que par certains camions\n",
    "- Chaque objet a un point de collecte spécifique\n",
    "- Le temps de parcours d’une arête varie au cours du temps (ce qui revient à faire varier sa longueur), pour représenter la variation du trafic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GIT Naming Convention\n",
    "Nous utilisons la convention suivante : https://www.conventionalcommits.org/en/v1.0.0/\n",
    "\n",
    "fix(vue) dans le cas où nous corrigeons un bug\n",
    "docs(UML) dans le cas de modifications mineures du texte ou des livrables\n",
    "feat(backup) ajout d'une nouvelle fonctionnalité\n",
    "BREAKING CHANGE:Explications si vous changez un élément critique de l'application\n",
    "Dans le cas d'une rupture composée d'un correctif ou d'un élément structurel, vous pouvez ajouter une explication.\n",
    "fix !(vue) : Commentaire"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Partie 1 : Modélisation<center>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notre projet se rapproche donc de celui du Voyageur de Commerce.\n",
    "On veut prouver que le projet ADEME est NP-Difficile et par extension NP-Complet.\n",
    "\n",
    "On cherche donc à prouver que le Voyageur de Commerce est NP-Complet car si ADEME est au moins tout aussi difficile que celui du voyageur et qu'il est NP-Complet alors notre projet est lui aussi NP-Complet.\n",
    "\n",
    "Rappelons la définition d'un problème NP-Complet :\n",
    "Un problème est NP-Complet si :\n",
    "    - Il est contenu dans NP\n",
    "    - Il est contenu dans NP-Difficile\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variables de Decisions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Variables :\n",
    "$ x_{ij} $ : variable d'état booléene symbolisant si l'arête est dans la solution. <br>\n",
    "$ ci_{ij} $ : regulation du traffic <br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Variables Constantes :\n",
    "$ c_{ij} $ : coût fixe de l'arête <br>\n",
    "V : un ensemble de ville <br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Contraintes :\n",
    "- Passer une seule et unique fois par chaque ville.\n",
    "- Revenir au depôt, au point de départ.\n",
    "- En arrivant sur un nœud, on repart systématiquement de celui-ci.\n",
    "- On ne peut pas faire de boucle et revenir sur son propre nœud.\n",
    "- Le trafic peut varier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fonction Objectif :\n",
    "On cherche à minimiser le coût de transport lié aux arêtes.\n",
    "\n",
    "$ minF = \\sum_{i\\in \\mathbb{N}} \\sum_{j\\in \\mathbb{N}} x_{ij} \\times ( c_{ij} \\times ci_{ij} ) $<br>\n",
    "$ \\sum_{\\in V x_{0i}}x_{0i} = 1 $ $i \\neq 0$<br>\n",
    "$ \\sum_{\\in V x_{j0} }x_{j0} = 1 $ $j \\neq 0$<br>\n",
    "$ \\sum_{x_ii}x_{ii}= 0  $<br>\n",
    "$ \\sum_{i\\in \\mathbb{N}}x_{ij} = 1 \\forall i\\in N  $<br>\n",
    "$ \\sum_{j\\in \\mathbb{N}}x_{ij} = 1 \\forall j\\in N  $<br>\n",
    "$ t_i + c_{ij} - R(1-x_{ij}) < t_j  $<br>\n",
    "$ \\sum_{i\\in \\mathbb{N}} \\sum_{j\\in \\mathbb{N}} x_{ij} \\times ( c_{ij} \\times ci_{ij} ) $ > 0 <br>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Complexité du Problème\n",
    "\n",
    "Rappel : Un problème est NP Complet si et seulement s'il fait partis de NP et peut être réduit à un problème similaire qui est dit NP Complet. Alors notre problème est dit au moins aussi complet que celui pour lequel il a été réduit. Il est donc lui aussi NP Complet.\n",
    "\n",
    "#### Demonstration de la NP Complétude de notre problème :\n",
    "\n",
    "Démontrons tout d'abord que notre problème est dans NP :\n",
    "\n",
    "Afin de démontrer son appartenance à NP, nous devons verifier si un certificat peut être vérifié en temps polynomial.\n",
    "\n",
    "Dans notre problème nous possédons :\n",
    "- Une suite de sommets formant un circuit. Ce circuit forme une boucle partant d'un point de départ passant par chaque sommet le plus proche et arrivant à ce même point. -> Cela peut se vérifier en temps linéaire $ O_n $\n",
    "- L'on passe qu'une seule et unique fois par chaque sommet -> Cela peut se vérifier en temps linéaire $ O_n $\n",
    "- Il faut que la somme du poids des arêtes parcourues donc le coup du circuit soit inférieur à $ k $ -> Cela peut se vérifier en temps constant $ O_1 $\n",
    "\n",
    "L'on possède donc un problème possédant les caractéristiques suivantes, nous avons donc vérifié que celui-ci est en temps linéaire.\n",
    "L'on peut affirmer qu'il est verifiable en temps polynomial.\n",
    "Notre problème appartient donc à NP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Passons à la démonstration afin de prouver son appartenance à NP Complet :\n",
    "\n",
    "Notre problème peut être réduit à celui du voyageur de commerce que l'on sait NP Difficile.\n",
    "Notre problème d'optimisation est donc au moins aussi difficile que celui du voyageur de commerce.\n",
    "Notre problème étant dans NP et NP Difficile, il est au moins aussi difficile que le voyageur du commerce, et donc également NP Complet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <center>Partie 2 : Implémentation et exploitation<center>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I/ Implémentation\n",
    "<br></br>\n",
    "Une fois la modélisation de notre problème établie et les métaheuristiques choisies, nous pouvons passer aux différentes implémentations de nos algorithmes. Afin d'élargir notre espace de recherche, nous avons décidé d'implémenter différents algorithmes, tels que :\n",
    "- l'algorithme de colonies de fourmis\n",
    "- l'algorithme du recuit simulé\n",
    "- l'algorithme génétique\n",
    "\n",
    "Cela nous permettra donc de comparer les différents algorithmes et de voir lesquels sont les plus efficaces.\n",
    "\n",
    "\n",
    "Chaque algorithme possède une version capable de déterminer un chemin optimal pour un graphe complet, ainsi qu'une autre version capable de réaliser la même tâche pour un graphe quelconque.\n",
    "\n",
    "Nous allons maintenant tester les différents algorithmes. Pour ce faire, 3 instances de test sont mise en place ci-dessous :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#imports common libs\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:32:49.402381500Z",
     "start_time": "2023-06-20T12:32:43.648515800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates generation Done !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swen AUBERTIN\\PycharmProjects\\Ademe\\generate.py:100: RuntimeWarning: invalid value encountered in divide\n",
      "  times = np.divide(d, np.nan_to_num(v))  # Time = Distance / Speeds\n"
     ]
    }
   ],
   "source": [
    "from generate import generate\n",
    "from complete_graphs.graph import Graph"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:32:49.479294700Z",
     "start_time": "2023-06-20T12:32:49.404377100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates generation Done !\n"
     ]
    }
   ],
   "source": [
    "# Instance avec 100 villes\n",
    "generate(X=100,Y=100,n=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:32:49.567989600Z",
     "start_time": "2023-06-20T12:32:49.480292600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Algorithmes avec graphe complet\n",
    "<br></br>\n",
    "##### Algorithme de colonies de fourmis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Code de l'aco\n",
    "\n",
    "\n",
    "def read_coordinates():\n",
    "    coordinates = []\n",
    "    with open('vendor/coords/list.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            index = int(parts[0])\n",
    "            x = float(parts[1])\n",
    "            y = float(parts[2])\n",
    "            coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def read_distance_matrix(file_path):\n",
    "    distance_matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            distances = [float(distance) for distance in line.strip().split()]\n",
    "            distance_matrix.append(distances)\n",
    "    return np.array(distance_matrix)\n",
    "distance_matrix = read_distance_matrix('vendor/coords/distances.txt')\n",
    "\n",
    "def read_cost_matrix():\n",
    "    cost_matrix = []\n",
    "    with open('vendor/coords/matrix.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            row = [float(value) if value != 'nan' else np.nan for value in line.strip().split()]\n",
    "            cost_matrix.append(row)\n",
    "    return np.array(cost_matrix)\n",
    "\n",
    "def choose_next_city(current_city, unvisited_cities, pheromone_matrix, distance_matrix, alpha, beta):\n",
    "    probabilities = []\n",
    "    total = 0\n",
    "\n",
    "    for city in unvisited_cities:\n",
    "        pheromone = pheromone_matrix[current_city][city] ** alpha\n",
    "        distance = distance_matrix[current_city][city] ** beta\n",
    "\n",
    "        # Avoid division by zero or NaN values\n",
    "        if distance == 0 or np.isnan(distance):\n",
    "            probabilities.append(0)\n",
    "        else:\n",
    "            probabilities.append(pheromone / distance)\n",
    "            total += pheromone / distance\n",
    "\n",
    "    if total == 0:\n",
    "        # If total is still zero, choose a random next city\n",
    "        return np.random.choice(unvisited_cities)\n",
    "\n",
    "    probabilities = [p / total for p in probabilities]\n",
    "    next_city_index = np.random.choice(range(len(unvisited_cities)), p=probabilities)\n",
    "    return unvisited_cities[next_city_index]\n",
    "def ant_colony(coordinates, distance_matrix, num_ants, alpha, beta, evaporation, nb_trucks, iterations):\n",
    "    num_cities = len(coordinates)\n",
    "\n",
    "    if nb_trucks == 1:\n",
    "        best_path = None\n",
    "        best_cost = float('inf')\n",
    "        pheromone_matrix = np.ones((num_cities, num_cities)) * evaporation\n",
    "\n",
    "        # Wrapping range with tqdm to create a progress bar\n",
    "        for _ in tqdm(range(iterations), desc=\"Running Ant Colony Optimization\"):\n",
    "            paths = []\n",
    "            costs = []\n",
    "\n",
    "            for _ in range(num_ants):\n",
    "                current_city = np.random.randint(0, num_cities)\n",
    "                unvisited_cities = list(range(num_cities))\n",
    "                unvisited_cities.remove(current_city)\n",
    "                path = [current_city]\n",
    "                cost = 0\n",
    "\n",
    "                while unvisited_cities:\n",
    "                    next_city = choose_next_city(current_city, unvisited_cities, pheromone_matrix,\n",
    "                                                 distance_matrix, alpha, beta)\n",
    "                    path.append(next_city)\n",
    "                    cost += distance_matrix[current_city][next_city]\n",
    "                    unvisited_cities.remove(next_city)\n",
    "                    current_city = next_city\n",
    "\n",
    "                path.append(path[0])\n",
    "                cost += distance_matrix[path[-2]][path[-1]]\n",
    "\n",
    "                paths.append(path)\n",
    "                costs.append(cost)\n",
    "\n",
    "                if cost < best_cost:\n",
    "                    best_path = path\n",
    "                    best_cost = cost\n",
    "\n",
    "            pheromone_matrix *= (1 - evaporation)\n",
    "\n",
    "            for i in range(num_ants):\n",
    "                for j in range(num_cities):\n",
    "                    pheromone_matrix[paths[i][j]][paths[i][j+1]] += 1 / costs[i]\n",
    "\n",
    "        return best_path, best_cost\n",
    "    else:\n",
    "        # Cas pour plusieurs camions avec clustering\n",
    "        distance_matrix = read_distance_matrix('vendor/coords/distances.txt')\n",
    "\n",
    "        # Création des clusters\n",
    "        clusters = [[] for _ in range(nb_trucks)]\n",
    "        num_cities = len(coordinates)\n",
    "\n",
    "        assigned = set()  # Villes déjà assignées à un cluster\n",
    "\n",
    "        for i in range(num_cities):\n",
    "            if i not in assigned:\n",
    "                nearest_city = np.argmin(distance_matrix[i])  # Indice de la ville la plus proche\n",
    "                cluster_id = len(assigned) % nb_trucks  # Identifiant du cluster\n",
    "                clusters[cluster_id].append(i)  # Ajouter la ville au cluster\n",
    "                assigned.add(i)  # Marquer la ville comme assignée\n",
    "                assigned.add(nearest_city)  # Marquer la ville la plus proche comme assignée\n",
    "\n",
    "        # Storing paths for all trucks\n",
    "        all_truck_paths = []\n",
    "        total_cost = 0\n",
    "\n",
    "        # Running ant colony optimization for each cluster\n",
    "        for cluster_id in range(nb_trucks):\n",
    "            cluster_coordinates = [coordinates[i] for i in clusters[cluster_id]]\n",
    "            cluster_distance_matrix = distance_matrix[clusters[cluster_id]][:, clusters[cluster_id]]\n",
    "\n",
    "            # Running ant colony optimization on the cluster\n",
    "            best_path, best_cost = ant_colony(cluster_coordinates, cluster_distance_matrix, num_ants, alpha, beta,\n",
    "                                              evaporation, nb_trucks=1, iterations=iterations)\n",
    "\n",
    "            # Adding paths and costs for each truck\n",
    "            all_truck_paths.append(best_path)\n",
    "            total_cost += best_cost\n",
    "\n",
    "        # Return all the paths and the total cost\n",
    "        return all_truck_paths, total_cost\n",
    "def running(num_ants = 20, alpha = 1, beta = 2, evaporation = 0.5, iterations = 100, perf_iterations = 1, nb_trucks = 2):\n",
    "    # Plot the CPU usage graph\n",
    "    cpu_percentages = []\n",
    "    memory_usages = []\n",
    "    timestamps = []\n",
    "\n",
    "    # Read coordinates and distance matrix\n",
    "    coordinates = read_coordinates()\n",
    "    distance_matrix = read_cost_matrix()\n",
    "    num_cities = len(coordinates)\n",
    "\n",
    "    writer = None\n",
    "\n",
    "    if perf_iterations > 1:\n",
    "        filename = 'vendor/benchmarks/ant_complete/'\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)  # create folder if it doesn't exist\n",
    "        benchfile = open(f\"{filename}/{datetime.datetime.now().strftime('%d-%m-%Y_%H-%M-%S')}.csv\", mode='w',newline='')# open file\n",
    "\n",
    "        writer = csv.writer(benchfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)  # create csv writer\n",
    "        writer.writerow([\"iteration\", \"runtime (ms)\", \"CPU time (ms)\", \"memory (mb)\", \"nb_nodes\", \"nb_edges\", \"cost\",\n",
    "                         \"path\"])  # write header\n",
    "\n",
    "    for i in range(perf_iterations):\n",
    "        # Start time and resource usage\n",
    "        start_time = time.time()\n",
    "        start_cpu_time = psutil.Process().cpu_times().user\n",
    "        start_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "\n",
    "        # Run the ant colony optimization algorithm\n",
    "        if nb_trucks == 1:\n",
    "            best_path, best_cost = ant_colony(coordinates, distance_matrix, num_ants, alpha, beta, evaporation, nb_trucks, iterations)\n",
    "        else:\n",
    "            all_truck_paths, total_cost = ant_colony(coordinates, distance_matrix, num_ants, alpha, beta, evaporation,\n",
    "                                                     nb_trucks, iterations)\n",
    "        # End time and resource usage\n",
    "        end_cpu_time = psutil.Process().cpu_times().user\n",
    "        end_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate execution time and resource usage\n",
    "        execution_time = end_time - start_time\n",
    "        cpu_time = end_cpu_time - start_cpu_time\n",
    "        memory_usage = end_memory_usage - start_memory_usage\n",
    "\n",
    "        if perf_iterations > 1:\n",
    "            if nb_trucks == 1:\n",
    "                writer.writerow([i, execution_time * 1000, cpu_time * 1000, memory_usage, num_cities, num_cities ** 2,\n",
    "                                 best_cost, best_path])\n",
    "            else :\n",
    "                writer.writerow([i, execution_time * 1000, cpu_time * 1000, memory_usage, num_cities, num_cities ** 2,\n",
    "                             total_cost, all_truck_paths])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Print results\n",
    "    if nb_trucks == 1:\n",
    "        print(\"Best path:\", best_path)\n",
    "        print(\"Best cost:\", best_cost)\n",
    "        np.savetxt('vendor/Coords_ant/road.txt', best_path, fmt='%.0f')\n",
    "    else:\n",
    "        print(\"Best paths:\", all_truck_paths)\n",
    "        print(\"Total cost:\", total_cost)\n",
    "        with open('vendor/Coords_ant/composite_road.txt', 'w') as file:\n",
    "            for i, truck_path in enumerate(all_truck_paths):\n",
    "                for city in truck_path:\n",
    "                    file.write(str(city) + '\\n')\n",
    "                if i < len(all_truck_paths) - 1:\n",
    "                    file.write('-----' + '\\n')\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")\n",
    "    print(\"CPU time:\", cpu_time, \"seconds\")\n",
    "    print(\"Memory usage:\", memory_usage, \"MB\")\n",
    "\n",
    "\n",
    "    # Plot CPU and memory usage in real-time\n",
    "    for i in range(int(execution_time) + 1):\n",
    "        cpu_percentages.append(psutil.cpu_percent())\n",
    "        memory_usages.append(psutil.Process().memory_info().rss / 1024 / 1024)\n",
    "        timestamps.append(i)\n",
    "\n",
    "        # Plot CPU usage graph\n",
    "        plt.subplot(211)\n",
    "        plt.plot(timestamps, cpu_percentages, color='blue')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('CPU Usage (%)')\n",
    "        plt.title('CPU Usage')\n",
    "\n",
    "        # Plot memory usage graph\n",
    "        plt.subplot(212)\n",
    "        plt.plot(timestamps, memory_usages, color='red')\n",
    "        plt.xlabel('Time (seconds)')\n",
    "        plt.ylabel('Memory Usage (MB)')\n",
    "        plt.title('Memory Usage')\n",
    "        plt.draw()\n",
    "    plt.show()\n",
    "\n",
    "def calculate_results():\n",
    "    # Path of the file containing the list of cities\n",
    "    cities_file_path = 'vendor/Coords_ant/road.txt'\n",
    "    composite_cities_file_path = 'vendor/Coords_ant/composite_road.txt'\n",
    "    # Path of the file containing the distance matrix\n",
    "    distances_file_path = 'vendor/coords/distances.txt'\n",
    "    times_file_path = 'vendor/coords/times.txt'\n",
    "    gas_file_path = 'vendor/coords/gas.txt'\n",
    "    gas_cost_file_path = 'vendor/coords/gas_cost.txt'\n",
    "    human_cost_file_path = 'vendor/coords/human_cost.txt'\n",
    "\n",
    "    # Read the list of cities from the file\n",
    "    with open(cities_file_path, 'r') as cities_file:\n",
    "        cities = [int(line.strip()) for line in cities_file]\n",
    "\n",
    "    # Read the distance matrix from the file\n",
    "    with open(distances_file_path, 'r') as distances_file:\n",
    "        distance_lines = [line.strip().split() for line in distances_file]\n",
    "        distance_matrix = [[float(distance) for distance in line] for line in distance_lines]\n",
    "\n",
    "    # Read the time matrix from the file\n",
    "    with open(times_file_path, 'r') as times_file:\n",
    "        time_lines = [line.strip().split() for line in times_file]\n",
    "        time_matrix = [[float(time) for time in line] for line in time_lines]\n",
    "\n",
    "    # Read the gas consumption matrix from the file\n",
    "    with open(gas_file_path, 'r') as gas_file:\n",
    "        gas_lines = [line.strip().split() for line in gas_file]\n",
    "        gas_matrix = [[float(gas) for gas in line] for line in gas_lines]\n",
    "\n",
    "    # Read the gas cost matrix from the file\n",
    "    with open(gas_cost_file_path, 'r') as gas_cost_file:\n",
    "        gas_cost_lines = [line.strip().split() for line in gas_cost_file]\n",
    "        gas_cost_matrix = [[float(gas_cost) for gas_cost in line] for line in gas_cost_lines]\n",
    "\n",
    "    # Read the human cost matrix from the file\n",
    "    with open(human_cost_file_path, 'r') as human_cost_file:\n",
    "        human_cost_lines = [line.strip().split() for line in human_cost_file]\n",
    "        human_cost_matrix = [[float(human) for human in line] for line in human_cost_lines]\n",
    "\n",
    "    if nb_trucks == 1:\n",
    "        # Calculate the total distance of the circuit\n",
    "        total_distance = 0\n",
    "        total_time = 0\n",
    "        total_gas = 0\n",
    "        total_gas_cost = 0\n",
    "        total_human_cost = 0\n",
    "        num_cities = len(cities)\n",
    "        for i in range(num_cities - 1):\n",
    "            start_city = cities[i]\n",
    "            end_city = cities[i + 1]\n",
    "            distance = distance_matrix[start_city][end_city]\n",
    "            time = time_matrix[start_city][end_city]\n",
    "            gas = gas_matrix[start_city][end_city]\n",
    "            gas_cost = gas_cost_matrix[start_city][end_city]\n",
    "            human_cost = human_cost_matrix[start_city][end_city]\n",
    "            total_distance += distance\n",
    "            total_time += time\n",
    "            total_gas += gas\n",
    "            total_gas_cost += gas_cost\n",
    "            total_human_cost += human_cost\n",
    "            hours = int(total_time)  # Integer part of hours\n",
    "            difference = total_time - hours  # Difference between the approximation and the integer part\n",
    "            minutes = int(difference * 60)  # Conversion of the difference to minutes\n",
    "\n",
    "        print(\"Distance:\", total_distance, \"km\")\n",
    "        print(\"Time:\", f\"{hours} hours {minutes} minutes\")\n",
    "        print(\"Gas consumption:\", total_gas, \"L\")\n",
    "        print(\"Gas cost:\", total_gas_cost, \"€\")\n",
    "        print(\"Human cost:\", total_human_cost, \"€\")\n",
    "    else:\n",
    "        # Cas pour plusieurs camions\n",
    "        with open(composite_cities_file_path, 'r') as composite_cities_file:\n",
    "            lines = composite_cities_file.readlines()\n",
    "            truck_paths = []  # Liste pour stocker les chemins de chaque camion\n",
    "            current_path = []  # Liste temporaire pour stocker le chemin courant\n",
    "            for line in lines:\n",
    "                if line.strip() != '-----':\n",
    "                    current_path.append(int(line.strip()))\n",
    "                else:\n",
    "                    truck_paths.append(current_path)\n",
    "                    current_path = []\n",
    "            if current_path:  # Ajouter le dernier chemin s'il n'est pas vide\n",
    "                truck_paths.append(current_path)\n",
    "\n",
    "        # Calculer la distance totale du circuit pour chaque camion\n",
    "        for truck_index, cities in enumerate(truck_paths):\n",
    "            total_distance = 0\n",
    "            total_time = 0\n",
    "            total_gas = 0\n",
    "            total_gas_cost = 0\n",
    "            total_human_cost = 0\n",
    "            num_cities = len(cities)\n",
    "            for i in range(num_cities - 1):\n",
    "                start_city = cities[i]\n",
    "                end_city = cities[i + 1]\n",
    "                distance = distance_matrix[start_city][end_city]\n",
    "                time = time_matrix[start_city][end_city]\n",
    "                gas = gas_matrix[start_city][end_city]\n",
    "                gas_cost = gas_cost_matrix[start_city][end_city]\n",
    "                human_cost = human_cost_matrix[start_city][end_city]\n",
    "                total_distance += distance\n",
    "                total_time += time\n",
    "                total_gas += gas\n",
    "                total_gas_cost += gas_cost\n",
    "                total_human_cost += human_cost\n",
    "\n",
    "            hours = int(total_time)  # Partie entière des heures\n",
    "            difference = total_time - hours  # Différence entre l'approximation et la partie entière\n",
    "            minutes = int(difference * 60)  # Conversion de la différence en minutes\n",
    "\n",
    "            print(f\"Truck {truck_index + 1}:\")\n",
    "            print(\"  Distance:\", total_distance, \"km\")\n",
    "            print(\"  Time:\", f\"{hours} hours {minutes} minutes\")\n",
    "            print(\"  Gas consumption:\", total_gas, \"L\")\n",
    "            print(\"  Gas cost:\", total_gas_cost, \"€\")\n",
    "            print(\"  Human cost:\", total_human_cost, \"€\")\n",
    "            print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:41:04.984110900Z",
     "start_time": "2023-06-20T12:41:04.960374100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Ant Colony Optimization: 100%|██████████| 100/100 [00:06<00:00, 15.60it/s]\n",
      "Running Ant Colony Optimization: 100%|██████████| 100/100 [00:06<00:00, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paths: [[34, 48, 35, 46, 37, 5, 17, 13, 41, 49, 36, 10, 11, 27, 1, 38, 4, 39, 6, 0, 43, 19, 28, 7, 42, 22, 15, 29, 32, 40, 44, 9, 3, 25, 18, 33, 31, 26, 8, 14, 12, 24, 2, 47, 23, 45, 16, 21, 30, 20, 34], [25, 8, 3, 42, 36, 15, 20, 9, 35, 41, 46, 34, 0, 29, 30, 6, 21, 4, 12, 17, 48, 22, 23, 44, 5, 16, 45, 39, 13, 26, 7, 2, 32, 33, 43, 47, 1, 11, 38, 49, 40, 10, 14, 28, 24, 18, 37, 19, 31, 27, 25]]\n",
      "Total cost: 1253.1800000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vendor/Coords_ant/composite_road.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m iterations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[0;32m      8\u001B[0m nb_trucks \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m---> 10\u001B[0m \u001B[43mrunning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_ants\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_ants\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnb_trucks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_trucks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevaporation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaporation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43miterations\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m calculate_results()\n",
      "Cell \u001B[1;32mIn[11], line 200\u001B[0m, in \u001B[0;36mrunning\u001B[1;34m(num_ants, alpha, beta, evaporation, iterations, perf_iterations, nb_trucks)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest paths:\u001B[39m\u001B[38;5;124m\"\u001B[39m, all_truck_paths)\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal cost:\u001B[39m\u001B[38;5;124m\"\u001B[39m, total_cost)\n\u001B[1;32m--> 200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvendor/Coords_ant/composite_road.txt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, truck_path \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(all_truck_paths):\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m city \u001B[38;5;129;01min\u001B[39;00m truck_path:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Ademe\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m     )\n\u001B[1;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'vendor/Coords_ant/composite_road.txt'"
     ]
    }
   ],
   "source": [
    "# Code avec paramètres pour lancer l'aco\n",
    "\n",
    "num_ants = 20\n",
    "alpha = 1\n",
    "beta = 2\n",
    "evaporation = 0.5\n",
    "iterations = 100\n",
    "nb_trucks = 2\n",
    "\n",
    "running(num_ants=num_ants, nb_trucks=nb_trucks, evaporation=evaporation, alpha=alpha, beta=beta, iterations=iterations)\n",
    "calculate_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:41:22.566544900Z",
     "start_time": "2023-06-20T12:41:09.515672500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Algorithme du recuit simulé"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code du recuit\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import psutil\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Paramètres de contrôle\n",
    "temp_init = 10000\n",
    "cooling = 0.995\n",
    "temp_min = 0.0001\n",
    "nb_trucks = 3\n",
    "reheat_threshold = 0.001\n",
    "reheat_value = 300\n",
    "max_reheat_count = 6\n",
    "\n",
    "# Chemin du fichier contenant la matrice de coûts\n",
    "cost_matrix_file_path = 'vendor/coords/matrix.txt'\n",
    "\n",
    "\n",
    "def read_coordinates():\n",
    "    coordinates = []\n",
    "    with open('vendor/coords/list.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            x = float(parts[1])\n",
    "            y = float(parts[2])\n",
    "            coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def read_cost_matrix(file_path):\n",
    "    cost_matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            row = [float(value) if value != 'nan' else np.nan for value in line.strip().split()]\n",
    "            cost_matrix.append(row)\n",
    "    return np.array(cost_matrix)\n",
    "\n",
    "\n",
    "def generate_random_tour(cost_matrix):\n",
    "    city_count = len(cost_matrix)\n",
    "    return random.sample(range(city_count), city_count)\n",
    "\n",
    "\n",
    "def distance(tour, cities):\n",
    "    distance = 0\n",
    "    for i in range(1, len(tour)):\n",
    "        distance += np.linalg.norm(np.array(cities[tour[i - 1]]) - np.array(cities[tour[i]]))\n",
    "    distance += np.linalg.norm(np.array(cities[tour[-1]]) - np.array(cities[0]))\n",
    "    return distance\n",
    "\n",
    "\n",
    "def split_tour(tour, num_trucks, cities):\n",
    "    city_count = len(tour)\n",
    "    city_coordinates = [cities[i] for i in tour]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_trucks, n_init=10, random_state=0).fit(city_coordinates)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    sub_tours = [[] for _ in range(num_trucks)]\n",
    "    for i, label in enumerate(labels):\n",
    "        sub_tours[label].append(tour[i])\n",
    "\n",
    "    for i in range(num_trucks):\n",
    "        if sub_tours[i][0] != 0:\n",
    "            sub_tours[i].insert(0, 0)\n",
    "        if sub_tours[i][-1] != 0:\n",
    "            sub_tours[i].append(0)\n",
    "\n",
    "    return sub_tours\n",
    "\n",
    "\n",
    "def simulated_annealing(cost_matrix, temp_init, cooling, temp_min, reheat_threshold, reheat_value, max_reheat_count):\n",
    "    start_time = time.time()\n",
    "    cities = read_coordinates()\n",
    "    current_tour = generate_random_tour(cost_matrix)\n",
    "    current_distance = distance(current_tour, cities)\n",
    "    best_tour = current_tour\n",
    "    best_distance = current_distance\n",
    "    temperature = temp_init\n",
    "    nb_iterations = 0\n",
    "    reheat_count = 0\n",
    "\n",
    "    while temperature > temp_min:\n",
    "        nb_iterations += 1\n",
    "\n",
    "        new_tour = copy.copy(current_tour)\n",
    "        swap_indices = random.sample(range(1, len(new_tour)), 2)\n",
    "        new_tour[swap_indices[0]], new_tour[swap_indices[1]] = new_tour[swap_indices[1]], new_tour[swap_indices[0]]\n",
    "\n",
    "        new_distance = distance(new_tour, cities)\n",
    "        delta_distance = new_distance - current_distance\n",
    "\n",
    "        if delta_distance < 0 or random.random() < math.exp(-delta_distance / temperature):\n",
    "            current_tour = new_tour\n",
    "            current_distance = new_distance\n",
    "\n",
    "        if current_distance < best_distance:\n",
    "            best_tour = current_tour\n",
    "            best_distance = current_distance\n",
    "\n",
    "        temperature *= cooling\n",
    "\n",
    "        if temperature < reheat_threshold and reheat_count < max_reheat_count:\n",
    "            temperature += reheat_value\n",
    "            reheat_count += 1\n",
    "\n",
    "    sub_tours = split_tour(best_tour, nb_trucks, cities)\n",
    "\n",
    "    total_distance = 0\n",
    "    for i, sub_tour in enumerate(sub_tours):\n",
    "        sub_tour_distance = distance(sub_tour, cities)\n",
    "        print(\"Tour {}: Length {}, Route: {}\".format(i + 1, sub_tour_distance, sub_tour))\n",
    "        total_distance += sub_tour_distance\n",
    "\n",
    "    print(\"Total distance: {}\".format(total_distance))\n",
    "    print(\"Execution time in seconds: \", time.time() - start_time)\n",
    "    print(\"Number of iterations: {}\".format(nb_iterations))\n",
    "\n",
    "    # Modification ici: écrire les sous-tours dans le fichier composite_road.txt\n",
    "    with open('vendor/coords_rec/composite_road.txt', 'w') as file:\n",
    "        for i, sub_tour in enumerate(sub_tours):\n",
    "            sub_tour_distance = distance(sub_tour, cities)\n",
    "            print(\"Tour {}: Length {}, Route: {}\".format(i + 1, sub_tour_distance, sub_tour))\n",
    "            # Écriture du sous-tour\n",
    "            for city_index in sub_tour:\n",
    "                file.write(str(city_index) + '\\n')\n",
    "            # Écriture de la démarcation (série de tirets) entre les sous-tours\n",
    "            if i < len(sub_tours) - 1:\n",
    "                file.write('-----\\n')\n",
    "            total_distance += sub_tour_distance\n",
    "\n",
    "    with open('vendor/coords_rec/road.txt', 'w') as file:\n",
    "        for city_index in best_tour:\n",
    "            file.write(str(city_index) + '\\n')\n",
    "    return best_tour, best_distance\n",
    "\n",
    "\n",
    "def calculate_results(best_tour):\n",
    "    cities_file_path = 'vendor/Coords_rec/road.txt'\n",
    "    distances_file_path = 'vendor/coords/distances.txt'\n",
    "    times_file_path = 'vendor/coords/times.txt'\n",
    "    gas_file_path = 'vendor/coords/gas.txt'\n",
    "    gas_cost_file_path = 'vendor/coords/gas_cost.txt'\n",
    "    human_cost_file_path = 'vendor/coords/human_cost.txt'\n",
    "\n",
    "    with open(cities_file_path, 'r') as cities_file:\n",
    "        cities = [int(line.strip()) for line in cities_file]\n",
    "\n",
    "    with open(distances_file_path, 'r') as distances_file:\n",
    "        distance_lines = [line.strip().split() for line in distances_file]\n",
    "        distance_matrix = [[float(distance) for distance in line] for line in distance_lines]\n",
    "\n",
    "    with open(times_file_path, 'r') as times_file:\n",
    "        time_lines = [line.strip().split() for line in times_file]\n",
    "        time_matrix = [[float(time) for time in line] for line in time_lines]\n",
    "\n",
    "    with open(gas_file_path, 'r') as gas_file:\n",
    "        gas_lines = [line.strip().split() for line in gas_file]\n",
    "        gas_matrix = [[float(gas) for gas in line] for line in gas_lines]\n",
    "\n",
    "    with open(gas_cost_file_path, 'r') as gas_cost_file:\n",
    "        gas_cost_lines = [line.strip().split() for line in gas_cost_file]\n",
    "        gas_cost_matrix = [[float(gas_cost) for gas_cost in line] for line in gas_cost_lines]\n",
    "\n",
    "    with open(human_cost_file_path, 'r') as human_cost_file:\n",
    "        human_cost_lines = [line.strip().split() for line in human_cost_file]\n",
    "        human_cost_matrix = [[float(human) for human in line] for line in human_cost_lines]\n",
    "\n",
    "    # Lire la matrice des distances\n",
    "    with open('vendor/coords/distances.txt', 'r') as distances_file:\n",
    "        distance_lines = [line.strip().split() for line in distances_file]\n",
    "        distance_matrix = [[float(distance) for distance in line] for line in distance_lines]\n",
    "\n",
    "    total_distance = 0\n",
    "    total_time = 0\n",
    "    total_gas = 0\n",
    "    total_gas_cost = 0\n",
    "    total_human_cost = 0\n",
    "    num_cities = len(cities) - 1\n",
    "\n",
    "    for i in range(num_cities - 1):\n",
    "        start_city = cities[i]\n",
    "        end_city = cities[i + 1]\n",
    "        distance = distance_matrix[start_city][end_city]\n",
    "        time = time_matrix[start_city][end_city]\n",
    "        gas = gas_matrix[start_city][end_city]\n",
    "        gas_cost = gas_cost_matrix[start_city][end_city]\n",
    "        human_cost = human_cost_matrix[start_city][end_city]\n",
    "        total_distance += distance\n",
    "        total_time += time\n",
    "        total_gas += gas\n",
    "        total_gas_cost += gas_cost\n",
    "        total_human_cost += human_cost\n",
    "\n",
    "    hours = int(total_time)\n",
    "    minutes = int((total_time - hours) * 60)\n",
    "\n",
    "    print(\"Distance:\", total_distance, \"km\")\n",
    "    print(\"Time:\", f\"{hours} hours {minutes} minutes\")\n",
    "    print(\"Gas consumption:\", total_gas, \"L\")\n",
    "    print(\"Gas cost:\", total_gas_cost, \"€\")\n",
    "    print(\"Human cost:\", total_human_cost, \"€\")\n",
    "\n",
    "\n",
    "\n",
    "perf_iterations=1\n",
    "\n",
    "writer = None\n",
    "if perf_iterations > 1:\n",
    "    filename = 'vendor/benchmarks/rec_complete/'\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)  # create folder if it doesn't exist\n",
    "    benchfile = open(f\"{filename}/{datetime.datetime.now().strftime('%d-%m-%Y_%H-%M-%S')}.csv\", mode='w',newline='')# open file\n",
    "\n",
    "    writer = csv.writer(benchfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)  # create csv writer\n",
    "    writer.writerow([\"iteration\", \"runtime (ms)\", \"CPU time (ms)\", \"memory (mb)\", \"nb_nodes\", \"nb_edges\", \"cost\",\n",
    "                     \"path\"])  # write header\n",
    "\n",
    "for i in range(perf_iterations):\n",
    "    # Start time and resource usage\n",
    "    start_time = time.time()\n",
    "    start_cpu_time = psutil.Process().cpu_times().user\n",
    "    start_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "\n",
    "    # Lancement de l'algorithme de recuit simulé\n",
    "    best_tour, best_distance = simulated_annealing(\n",
    "        read_cost_matrix(cost_matrix_file_path), temp_init, cooling, temp_min, reheat_threshold, reheat_value,\n",
    "        max_reheat_count)\n",
    "\n",
    "    # End time and resource usage\n",
    "    end_cpu_time = psutil.Process().cpu_times().user\n",
    "    end_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate execution time and resource usage\n",
    "    execution_time = end_time - start_time\n",
    "    cpu_time = end_cpu_time - start_cpu_time\n",
    "    memory_usage = end_memory_usage - start_memory_usage\n",
    "\n",
    "    num_cities = len(best_tour)\n",
    "\n",
    "    if perf_iterations > 1:\n",
    "        writer.writerow([i, execution_time * 1000, cpu_time * 1000, memory_usage, num_cities, num_cities ** 2, best_distance, best_tour])\n",
    "\n",
    "# Calcul et affichage des résultats\n",
    "calculate_results(best_tour)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code avec paramètres pour lancer le recuit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Algorithme génétique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Code du génétique\n",
    "def genetic(nb_generations, nb_solutions, nb_kept_solutions, mutation_rate, start_node,graph=None):\n",
    "    # graph.node_and_edges_from_adjacency_matrix([[0, 0, 0, 0, 0, 0, 247, 0, 375, 0], [0, 0, 0, 4, 0, 0, 140, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 323, 457], [0, 4, 0, 0, 0, 0, 0, 287, 0, 0], [0, 0, 0, 0, 0, 0, 334, 0, 0, 116], [0, 0, 0, 0, 0, 0, 552, 0, 0, 485], [247, 140, 0, 0, 334, 552, 0, 0, 0, 0], [0, 0, 0, 287, 0, 0, 0, 0, 373, 0], [375, 0, 323, 0, 0, 0, 0, 373, 0, 0], [0, 0, 457, 0, 116, 485, 0, 0, 0, 0]])\n",
    "    if graph is None:\n",
    "        graph = Graph()\n",
    "        graph.generate_random_graph(100)\n",
    "    # graph.plot_graph()\n",
    "\n",
    "    generation = []\n",
    "    solutions = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for _ in range(nb_generations):\n",
    "        print(\"generation\",_+1)\n",
    "        if len(solutions) == nb_kept_solutions:\n",
    "            solutions.extend(\n",
    "                random_solution(graph, start_node)\n",
    "                for __ in range(nb_solutions - nb_kept_solutions)\n",
    "            )\n",
    "        else:\n",
    "            solutions.extend(\n",
    "                random_solution(graph, start_node)\n",
    "                for __ in range(nb_solutions)\n",
    "            )\n",
    "\n",
    "        generation = fitness(graph, solutions, generation)\n",
    "        if _ == nb_generations-1:\n",
    "            print('best found path before crossover and mutation :', generation[0])\n",
    "        # print('fitness done')\n",
    "\n",
    "        best_solutions = [generation[0][1]]\n",
    "        start = time.time()\n",
    "        best_solutions.extend(\n",
    "            cross_over(\n",
    "                generation[i][1], generation[i + 1][1], graph, start_node\n",
    "            )\n",
    "            for i in range(nb_kept_solutions - 1)\n",
    "        )\n",
    "        print('crossover time :',time.time() - start, 's')\n",
    "        # print('crossover done')\n",
    "\n",
    "        start = time.time()\n",
    "        for i in range(len(best_solutions)):\n",
    "            best_solutions[i] = mutation(best_solutions[i], mutation_rate, graph)\n",
    "\n",
    "        print('all mutation time :', time.time() - start, 's')\n",
    "        solutions = best_solutions\n",
    "        generation = []\n",
    "\n",
    "    best_found_path = fitness(graph,solutions, generation)[0]\n",
    "    print('best found path :',best_found_path)\n",
    "    print(len(best_found_path[1]))\n",
    "\n",
    "    print(\"best path found in\", (time.time() - start_time) * 1000, \"ms\")\n",
    "\n",
    "    return best_found_path\n",
    "\n",
    "def fitness(graph, solutions, gen):\n",
    "    for i in solutions:\n",
    "        path_cost = sum(\n",
    "            graph.get_edge(i[j], i[(j + 1)]).weight for j in range(len(i) - 1)\n",
    "        )\n",
    "        gen.append((path_cost, i))\n",
    "    gen= sorted(gen, key=lambda x: x[0])\n",
    "    return gen\n",
    "\n",
    "def random_solution(graph, start_node):\n",
    "\n",
    "    path = []\n",
    "    nodes_list = list(graph.nodes.keys())\n",
    "    path.append(start_node)\n",
    "    nodes_list.pop(nodes_list.index(start_node))\n",
    "    next_node = random.choice(graph.nodes[start_node].neighbors)\n",
    "    while nodes_list or path[0] != path[-1]:\n",
    "        path.append(next_node)\n",
    "        if next_node in nodes_list:\n",
    "            nodes_list.pop(nodes_list.index(next_node))\n",
    "\n",
    "        next_node = random.choice(graph.nodes[next_node].neighbors)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "def cross_over(parent_1,parent_2,graph,start_node):\n",
    "    def create_indices_dict(parent):\n",
    "        indices_dict = defaultdict(list)\n",
    "        for index, node in enumerate(parent):\n",
    "            indices_dict[node].append(index)\n",
    "        return indices_dict\n",
    "\n",
    "    new_path = [start_node]\n",
    "    nodes_list = list(graph.nodes.keys())\n",
    "    nodes_list.remove(start_node)\n",
    "\n",
    "    indices_dict_parent_1 = create_indices_dict(parent_1)\n",
    "    indices_dict_parent_2 = create_indices_dict(parent_2)\n",
    "\n",
    "    current_node = start_node\n",
    "    while nodes_list or new_path[0] != new_path[-1]:\n",
    "        # indices = [index for index, node in enumerate(parent_1) if node == current_node]\n",
    "        indices = indices_dict_parent_1.get(current_node, [])\n",
    "        chosen_index_parent_1 = random.choice(indices)\n",
    "        next_node_parent_1 = parent_1[chosen_index_parent_1 + 1] if chosen_index_parent_1 < len(parent_1) - 1 else None\n",
    "\n",
    "        # indices = [index for index, node in enumerate(parent_2) if node == current_node]\n",
    "        indices = indices_dict_parent_2.get(current_node, [])\n",
    "        chosen_index_parent_2 = random.choice(indices)\n",
    "        next_node_parent_2 = parent_2[chosen_index_parent_2 + 1] if chosen_index_parent_2 < len(parent_2) - 1 else None\n",
    "\n",
    "        # Choose randomly between next_node_parent_1 and next_node_parent_2\n",
    "        next_node = random.choice([next_node_parent_1, next_node_parent_2])\n",
    "        if not next_node:\n",
    "            if valid_next_nodes := [\n",
    "                node\n",
    "                for node in graph.nodes[current_node].neighbors\n",
    "                if node in nodes_list\n",
    "            ]:\n",
    "                next_node = random.choice(valid_next_nodes)\n",
    "            else:\n",
    "                next_node = random.choice(graph.nodes[current_node].neighbors)\n",
    "\n",
    "        new_path.append(next_node)\n",
    "        if next_node in nodes_list:\n",
    "            nodes_list.remove(next_node)\n",
    "        current_node = next_node\n",
    "    return new_path\n",
    "\n",
    "\n",
    "def mutation(sol, rate, graph):\n",
    "    def is_valid_path(path, i1, i2, graph):\n",
    "        if graph.get_edge(path[i1],path[i1+1]) and graph.get_edge(path[i1], path[i1 - 1]) and graph.get_edge(path[i2], path[i2 + 1]) and graph.get_edge(path[i2], path[i2 - 1]):\n",
    "            return True\n",
    "        # return all(graph.get_edge(path[i], path[i + 1]) for i in range(len(path) - 1))\n",
    "\n",
    "    if random.random() <= rate:\n",
    "        for _ in range(len(sol)*10):  # Limit to a certain number of tries\n",
    "            # Choose two node indices at random from the solution\n",
    "            idx1, idx2 = random.sample(range(1, len(sol)-1), 2)\n",
    "\n",
    "            if sol[idx1] == sol[idx2]:\n",
    "                continue\n",
    "\n",
    "            # Swap the nodes at these indices\n",
    "            mutated_sol = list(sol)\n",
    "            mutated_sol[idx1], mutated_sol[idx2] = sol[idx2], sol[idx1]\n",
    "\n",
    "            # Verify if the mutated solution is still a valid path\n",
    "            if is_valid_path(mutated_sol, idx1, idx2, graph):\n",
    "                return mutated_sol\n",
    "    # If no valid mutation was found, return the original solution\n",
    "    return sol"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:41:31.811440300Z",
     "start_time": "2023-06-20T12:41:31.794457200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation 1\n",
      "crossover time : 0.0374143123626709 s\n",
      "all mutation time : 0.0 s\n",
      "generation 2\n",
      "crossover time : 0.03789854049682617 s\n",
      "all mutation time : 0.0 s\n",
      "generation 3\n",
      "crossover time : 0.028924942016601562 s\n",
      "all mutation time : 0.0 s\n",
      "generation 4\n",
      "crossover time : 0.028923749923706055 s\n",
      "all mutation time : 0.0 s\n",
      "generation 5\n",
      "crossover time : 0.027925729751586914 s\n",
      "all mutation time : 0.0 s\n",
      "generation 6\n",
      "crossover time : 0.02493143081665039 s\n",
      "all mutation time : 0.0 s\n",
      "generation 7\n",
      "crossover time : 0.027498245239257812 s\n",
      "all mutation time : 0.0 s\n",
      "generation 8\n",
      "crossover time : 0.025438547134399414 s\n",
      "all mutation time : 0.0 s\n",
      "generation 9\n",
      "crossover time : 0.027894973754882812 s\n",
      "all mutation time : 0.0 s\n",
      "generation 10\n",
      "best found path before crossover and mutation : (269.48999999999995, ['0', '53', '7', '84', '88', '31', '68', '99', '88', '64', '42', '98', '5', '78', '58', '81', '66', '56', '8', '33', '46', '95', '99', '16', '98', '62', '83', '46', '92', '83', '28', '41', '64', '96', '24', '68', '93', '62', '90', '86', '36', '83', '52', '19', '31', '63', '20', '96', '71', '0', '53', '44', '16', '4', '75', '39', '33', '21', '69', '59', '0', '1', '74', '10', '19', '25', '62', '19', '61', '9', '25', '38', '43', '38', '53', '45', '63', '55', '92', '85', '91', '74', '20', '7', '49', '17', '86', '35', '94', '87', '16', '8', '32', '48', '88', '55', '9', '67', '98', '2', '0', '49', '16', '27', '38', '95', '67', '33', '18', '35', '65', '13', '15', '84', '73', '62', '81', '88', '48', '58', '98', '10', '58', '14', '58', '13', '80', '51', '11', '17', '84', '98', '13', '20', '6', '70', '82', '79', '68', '60', '99', '15', '64', '13', '11', '41', '97', '66', '30', '23', '87', '1', '20', '78', '57', '49', '39', '30', '88', '6', '52', '74', '92', '19', '71', '27', '57', '69', '45', '1', '37', '1', '74', '38', '94', '54', '41', '77', '54', '90', '4', '50', '61', '64', '77', '40', '53', '6', '14', '82', '71', '82', '54', '72', '32', '74', '23', '88', '51', '10', '62', '41', '67', '44', '26', '3', '78', '68', '49', '60', '64', '72', '60', '80', '57', '84', '27', '88', '13', '70', '24', '94', '38', '71', '29', '35', '47', '40', '53', '43', '89', '57', '49', '97', '76', '67', '8', '91', '6', '54', '70', '34', '66', '0', '84', '80', '3', '19', '68', '12', '62', '53', '10', '50', '76', '50', '66', '1', '84', '52', '32', '44', '6', '32', '79', '35', '22', '15', '88', '39', '95', '83', '56', '51', '71', '15', '56', '60', '32', '80', '51', '13', '61', '89', '75', '40', '84', '73', '52', '25', '39', '34', '50', '90', '82', '61', '87', '52', '74', '81', '96', '67', '88', '89', '79', '72', '99', '55', '20', '0'])\n",
      "crossover time : 0.025898456573486328 s\n",
      "all mutation time : 0.0 s\n",
      "best found path : (269.48999999999995, ['0', '53', '7', '84', '88', '31', '68', '99', '88', '64', '42', '98', '5', '78', '58', '81', '66', '56', '8', '33', '46', '95', '99', '16', '98', '62', '83', '46', '92', '83', '28', '41', '64', '96', '24', '68', '93', '62', '90', '86', '36', '83', '52', '19', '31', '63', '20', '96', '71', '0', '53', '44', '16', '4', '75', '39', '33', '21', '69', '59', '0', '1', '74', '10', '19', '25', '62', '19', '61', '9', '25', '38', '43', '38', '53', '45', '63', '55', '92', '85', '91', '74', '20', '7', '49', '17', '86', '35', '94', '87', '16', '8', '32', '48', '88', '55', '9', '67', '98', '2', '0', '49', '16', '27', '38', '95', '67', '33', '18', '35', '65', '13', '15', '84', '73', '62', '81', '88', '48', '58', '98', '10', '58', '14', '58', '13', '80', '51', '11', '17', '84', '98', '13', '20', '6', '70', '82', '79', '68', '60', '99', '15', '64', '13', '11', '41', '97', '66', '30', '23', '87', '1', '20', '78', '57', '49', '39', '30', '88', '6', '52', '74', '92', '19', '71', '27', '57', '69', '45', '1', '37', '1', '74', '38', '94', '54', '41', '77', '54', '90', '4', '50', '61', '64', '77', '40', '53', '6', '14', '82', '71', '82', '54', '72', '32', '74', '23', '88', '51', '10', '62', '41', '67', '44', '26', '3', '78', '68', '49', '60', '64', '72', '60', '80', '57', '84', '27', '88', '13', '70', '24', '94', '38', '71', '29', '35', '47', '40', '53', '43', '89', '57', '49', '97', '76', '67', '8', '91', '6', '54', '70', '34', '66', '0', '84', '80', '3', '19', '68', '12', '62', '53', '10', '50', '76', '50', '66', '1', '84', '52', '32', '44', '6', '32', '79', '35', '22', '15', '88', '39', '95', '83', '56', '51', '71', '15', '56', '60', '32', '80', '51', '13', '61', '89', '75', '40', '84', '73', '52', '25', '39', '34', '50', '90', '82', '61', '87', '52', '74', '81', '96', '67', '88', '89', '79', '72', '99', '55', '20', '0'])\n",
      "310\n",
      "best path found in 1034.3947410583496 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "(269.48999999999995,\n ['0',\n  '53',\n  '7',\n  '84',\n  '88',\n  '31',\n  '68',\n  '99',\n  '88',\n  '64',\n  '42',\n  '98',\n  '5',\n  '78',\n  '58',\n  '81',\n  '66',\n  '56',\n  '8',\n  '33',\n  '46',\n  '95',\n  '99',\n  '16',\n  '98',\n  '62',\n  '83',\n  '46',\n  '92',\n  '83',\n  '28',\n  '41',\n  '64',\n  '96',\n  '24',\n  '68',\n  '93',\n  '62',\n  '90',\n  '86',\n  '36',\n  '83',\n  '52',\n  '19',\n  '31',\n  '63',\n  '20',\n  '96',\n  '71',\n  '0',\n  '53',\n  '44',\n  '16',\n  '4',\n  '75',\n  '39',\n  '33',\n  '21',\n  '69',\n  '59',\n  '0',\n  '1',\n  '74',\n  '10',\n  '19',\n  '25',\n  '62',\n  '19',\n  '61',\n  '9',\n  '25',\n  '38',\n  '43',\n  '38',\n  '53',\n  '45',\n  '63',\n  '55',\n  '92',\n  '85',\n  '91',\n  '74',\n  '20',\n  '7',\n  '49',\n  '17',\n  '86',\n  '35',\n  '94',\n  '87',\n  '16',\n  '8',\n  '32',\n  '48',\n  '88',\n  '55',\n  '9',\n  '67',\n  '98',\n  '2',\n  '0',\n  '49',\n  '16',\n  '27',\n  '38',\n  '95',\n  '67',\n  '33',\n  '18',\n  '35',\n  '65',\n  '13',\n  '15',\n  '84',\n  '73',\n  '62',\n  '81',\n  '88',\n  '48',\n  '58',\n  '98',\n  '10',\n  '58',\n  '14',\n  '58',\n  '13',\n  '80',\n  '51',\n  '11',\n  '17',\n  '84',\n  '98',\n  '13',\n  '20',\n  '6',\n  '70',\n  '82',\n  '79',\n  '68',\n  '60',\n  '99',\n  '15',\n  '64',\n  '13',\n  '11',\n  '41',\n  '97',\n  '66',\n  '30',\n  '23',\n  '87',\n  '1',\n  '20',\n  '78',\n  '57',\n  '49',\n  '39',\n  '30',\n  '88',\n  '6',\n  '52',\n  '74',\n  '92',\n  '19',\n  '71',\n  '27',\n  '57',\n  '69',\n  '45',\n  '1',\n  '37',\n  '1',\n  '74',\n  '38',\n  '94',\n  '54',\n  '41',\n  '77',\n  '54',\n  '90',\n  '4',\n  '50',\n  '61',\n  '64',\n  '77',\n  '40',\n  '53',\n  '6',\n  '14',\n  '82',\n  '71',\n  '82',\n  '54',\n  '72',\n  '32',\n  '74',\n  '23',\n  '88',\n  '51',\n  '10',\n  '62',\n  '41',\n  '67',\n  '44',\n  '26',\n  '3',\n  '78',\n  '68',\n  '49',\n  '60',\n  '64',\n  '72',\n  '60',\n  '80',\n  '57',\n  '84',\n  '27',\n  '88',\n  '13',\n  '70',\n  '24',\n  '94',\n  '38',\n  '71',\n  '29',\n  '35',\n  '47',\n  '40',\n  '53',\n  '43',\n  '89',\n  '57',\n  '49',\n  '97',\n  '76',\n  '67',\n  '8',\n  '91',\n  '6',\n  '54',\n  '70',\n  '34',\n  '66',\n  '0',\n  '84',\n  '80',\n  '3',\n  '19',\n  '68',\n  '12',\n  '62',\n  '53',\n  '10',\n  '50',\n  '76',\n  '50',\n  '66',\n  '1',\n  '84',\n  '52',\n  '32',\n  '44',\n  '6',\n  '32',\n  '79',\n  '35',\n  '22',\n  '15',\n  '88',\n  '39',\n  '95',\n  '83',\n  '56',\n  '51',\n  '71',\n  '15',\n  '56',\n  '60',\n  '32',\n  '80',\n  '51',\n  '13',\n  '61',\n  '89',\n  '75',\n  '40',\n  '84',\n  '73',\n  '52',\n  '25',\n  '39',\n  '34',\n  '50',\n  '90',\n  '82',\n  '61',\n  '87',\n  '52',\n  '74',\n  '81',\n  '96',\n  '67',\n  '88',\n  '89',\n  '79',\n  '72',\n  '99',\n  '55',\n  '20',\n  '0'])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code avec paramètres pour lancer le génétique\n",
    "\n",
    "genetic_graph = Graph()\n",
    "genetic_graph.graph_from_matrix_file('vendor/Coords/matrix.txt')\n",
    "\n",
    "nb_gen = 10\n",
    "nb_sol = 100\n",
    "nb_kept_sol = 20\n",
    "mut_rate = .25\n",
    "start_n = '0'\n",
    "\n",
    "\n",
    "genetic(graph=genetic_graph,nb_generations=nb_gen, nb_solutions=nb_sol, nb_kept_solutions=nb_kept_sol, mutation_rate=mut_rate, start_node=start_n)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T12:42:34.351791900Z",
     "start_time": "2023-06-20T12:42:30.621980600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Algorithmes avec graphe quelconque\n",
    "<br></br>\n",
    "##### Création de l'instance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code pour créer l'instance\n",
    "graph=Graph()\n",
    "graph.generate_random_graph(10, 0.5)\n",
    "graph.print_adjency_matrix()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Algorithme de colonies de fourmis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code de l'aco"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code avec paramètres pour lancer l'aco"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Algorithme du recuit simulé"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code du recuit\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import psutil\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_coordinates():\n",
    "    coordinates = []\n",
    "    with open('vendor/Coords/list.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            x = float(parts[1])\n",
    "            y = float(parts[2])\n",
    "            coordinates.append((x, y))\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def read_cost_matrix(file_path):\n",
    "    cost_matrix = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            row = [float(value) if value != 'nan' else np.nan for value in line.strip().split()]\n",
    "            cost_matrix.append(row)\n",
    "    return np.array(cost_matrix)\n",
    "\n",
    "\n",
    "def generate_random_tour(cost_matrix):\n",
    "    city_count = len(cost_matrix)\n",
    "    return random.sample(range(city_count), city_count)\n",
    "\n",
    "\n",
    "def distance(tour, cities):\n",
    "    distance = 0\n",
    "    for i in range(1, len(tour)):\n",
    "        distance += np.linalg.norm(np.array(cities[tour[i - 1]]) - np.array(cities[tour[i]]))\n",
    "    distance += np.linalg.norm(np.array(cities[tour[-1]]) - np.array(cities[0]))\n",
    "    return distance\n",
    "\n",
    "\n",
    "def split_tour(tour, num_trucks, cities):\n",
    "    city_count = len(tour)\n",
    "    city_coordinates = [cities[i] for i in tour]\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_trucks, n_init=10, random_state=0).fit(city_coordinates)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    sub_tours = [[] for _ in range(num_trucks)]\n",
    "    for i, label in enumerate(labels):\n",
    "        sub_tours[label].append(tour[i])\n",
    "\n",
    "    for i in range(num_trucks):\n",
    "        if sub_tours[i][0] != 0:\n",
    "            sub_tours[i].insert(0, 0)\n",
    "        if sub_tours[i][-1] != 0:\n",
    "            sub_tours[i].append(0)\n",
    "\n",
    "    return sub_tours\n",
    "\n",
    "\n",
    "def simulated_annealing(cost_matrix, temp_init, cooling, temp_min, reheat_threshold, reheat_value, max_reheat_count):\n",
    "    start_time = time.time()\n",
    "    cities = read_coordinates()\n",
    "    current_tour = generate_random_tour(cost_matrix)\n",
    "    current_distance = distance(current_tour, cities)\n",
    "    best_tour = current_tour\n",
    "    best_distance = current_distance\n",
    "    temperature = temp_init\n",
    "    nb_iterations = 0\n",
    "    reheat_count = 0\n",
    "    pbar = tqdm(total=max_reheat_count, desc=\"Simulated Annealing - Reheating\", position=0, leave=True,\n",
    "                bar_format=\"{desc}: {percentage:.2f}%\")\n",
    "\n",
    "    while temperature > temp_min:\n",
    "        nb_iterations += 1\n",
    "\n",
    "        new_tour = copy.copy(current_tour)\n",
    "        swap_indices = random.sample(range(1, len(new_tour)), 2)\n",
    "        new_tour[swap_indices[0]], new_tour[swap_indices[1]] = new_tour[swap_indices[1]], new_tour[swap_indices[0]]\n",
    "\n",
    "        new_distance = distance(new_tour, cities)\n",
    "        delta_distance = new_distance - current_distance\n",
    "\n",
    "        if delta_distance < 0 or random.random() < math.exp(-delta_distance / temperature):\n",
    "            current_tour = new_tour\n",
    "            current_distance = new_distance\n",
    "\n",
    "        if current_distance < best_distance:\n",
    "            best_tour = current_tour\n",
    "            best_distance = current_distance\n",
    "\n",
    "        temperature *= cooling\n",
    "\n",
    "        if temperature < reheat_threshold and reheat_count < max_reheat_count:\n",
    "            temperature += reheat_value\n",
    "            reheat_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    sub_tours = split_tour(best_tour, nb_trucks, cities)\n",
    "\n",
    "    total_distance = 0\n",
    "    for i, sub_tour in enumerate(sub_tours):\n",
    "        sub_tour_distance = distance(sub_tour, cities)\n",
    "        print(\"Tour {}: Route: {}\".format(i + 1, sub_tour))\n",
    "        total_distance += sub_tour_distance\n",
    "\n",
    "    print(\"Total distance: {}\".format(total_distance))\n",
    "    print(\"Execution time in seconds: \", time.time() - start_time)\n",
    "    print(\"Number of iterations: {}\".format(nb_iterations))\n",
    "\n",
    "    # Modification ici: écrire les sous-tours dans le fichier composite_road.txt\n",
    "    with open('vendor/coords_rec/composite_road.txt', 'w') as file:\n",
    "        for i, sub_tour in enumerate(sub_tours):\n",
    "            sub_tour_distance = distance(sub_tour, cities)\n",
    "            # Écriture du sous-tour\n",
    "            for city_index in sub_tour:\n",
    "                file.write(str(city_index) + '\\n')\n",
    "            # Écriture de la démarcation (série de tirets) entre les sous-tours\n",
    "            if i < len(sub_tours) - 1:\n",
    "                file.write('-----\\n')\n",
    "            total_distance += sub_tour_distance\n",
    "\n",
    "    with open('vendor/coords_rec/road.txt', 'w') as file:\n",
    "        for city_index in best_tour:\n",
    "            file.write(str(city_index) + '\\n')\n",
    "    pbar.close()\n",
    "    return best_tour, best_distance\n",
    "\n",
    "\n",
    "def calculate_results(best_tour):\n",
    "    cities_file_path = 'vendor/Coords_rec/road.txt'\n",
    "    distances_file_path = 'vendor/Coords/distances.txt'\n",
    "    times_file_path = 'vendor/Coords/times.txt'\n",
    "    gas_file_path = 'vendor/Coords/gas.txt'\n",
    "    gas_cost_file_path = 'vendor/Coords/gas_cost.txt'\n",
    "    human_cost_file_path = 'vendor/Coords/human_cost.txt'\n",
    "\n",
    "    with open(cities_file_path, 'r') as cities_file:\n",
    "        cities = [int(line.strip()) for line in cities_file]\n",
    "\n",
    "    with open(distances_file_path, 'r') as distances_file:\n",
    "        distance_lines = [line.strip().split() for line in distances_file]\n",
    "        distance_matrix = [[float(distance) for distance in line] for line in distance_lines]\n",
    "\n",
    "    with open(times_file_path, 'r') as times_file:\n",
    "        time_lines = [line.strip().split() for line in times_file]\n",
    "        time_matrix = [[float(time) for time in line] for line in time_lines]\n",
    "\n",
    "    with open(gas_file_path, 'r') as gas_file:\n",
    "        gas_lines = [line.strip().split() for line in gas_file]\n",
    "        gas_matrix = [[float(gas) for gas in line] for line in gas_lines]\n",
    "\n",
    "    with open(gas_cost_file_path, 'r') as gas_cost_file:\n",
    "        gas_cost_lines = [line.strip().split() for line in gas_cost_file]\n",
    "        gas_cost_matrix = [[float(gas_cost) for gas_cost in line] for line in gas_cost_lines]\n",
    "\n",
    "    with open(human_cost_file_path, 'r') as human_cost_file:\n",
    "        human_cost_lines = [line.strip().split() for line in human_cost_file]\n",
    "        human_cost_matrix = [[float(human) for human in line] for line in human_cost_lines]\n",
    "\n",
    "    total_distance = 0\n",
    "    total_time = 0\n",
    "    total_gas = 0\n",
    "    total_gas_cost = 0\n",
    "    total_human_cost = 0\n",
    "    num_cities = len(cities) - 1\n",
    "\n",
    "    for i in range(num_cities - 1):\n",
    "        start_city = cities[i]\n",
    "        end_city = cities[i + 1]\n",
    "        distance = round(distance_matrix[start_city][end_city], 2)\n",
    "        time = round(time_matrix[start_city][end_city], 2)\n",
    "        gas = round(gas_matrix[start_city][end_city])\n",
    "        gas_cost = round(gas_cost_matrix[start_city][end_city], 2)\n",
    "        human_cost = round(human_cost_matrix[start_city][end_city])\n",
    "        total_distance += distance\n",
    "        total_time += time\n",
    "        total_gas += gas\n",
    "        total_gas_cost += gas_cost\n",
    "        total_human_cost += human_cost\n",
    "\n",
    "    hours = int(total_time)\n",
    "    minutes = int((total_time - hours) * 60)\n",
    "\n",
    "    print(\"Distance:\", total_distance, \"km\")\n",
    "    print(\"Time:\", f\"{hours} hours {minutes} minutes\")\n",
    "    print(\"Gas consumption:\", total_gas, \"L\")\n",
    "    print(\"Gas cost:\", total_gas_cost, \"€\")\n",
    "    print(\"Human cost:\", total_human_cost, \"€\")\n",
    "\n",
    "def running(temp_init = 10000,\n",
    "cooling = 0.995,\n",
    "temp_min = 0.0001,\n",
    "nb_trucks = 1,\n",
    "reheat_threshold = 0.001,\n",
    "reheat_value = 300,\n",
    "max_reheat_count = 6,\n",
    "perf_iterations=1):\n",
    "    writer = None\n",
    "    if perf_iterations > 1:\n",
    "        filename = 'vendor/benchmarks/rec_complete/'\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)  # create folder if it doesn't exist\n",
    "        benchfile = open(f\"{filename}/{datetime.datetime.now().strftime('%d-%m-%Y_%H-%M-%S')}.csv\", mode='w',newline='')# open file\n",
    "\n",
    "        writer = csv.writer(benchfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)  # create csv writer\n",
    "        writer.writerow([\"iteration\", \"runtime (ms)\", \"CPU time (ms)\", \"memory (mb)\", \"nb_nodes\", \"nb_edges\", \"cost\",\n",
    "                         \"path\"])  # write header\n",
    "\n",
    "    for i in range(perf_iterations):\n",
    "        # Start time and resource usage\n",
    "        start_time = time.time()\n",
    "        start_cpu_time = psutil.Process().cpu_times().user\n",
    "        start_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "\n",
    "        # Lancement de l'algorithme de recuit simulé\n",
    "        best_tour, best_distance = simulated_annealing(\n",
    "            read_cost_matrix(cost_matrix_file_path), temp_init, cooling, temp_min, reheat_threshold, reheat_value,\n",
    "            max_reheat_count)\n",
    "\n",
    "        # End time and resource usage\n",
    "        end_cpu_time = psutil.Process().cpu_times().user\n",
    "        end_memory_usage = psutil.Process().memory_info().rss / 1024 / 1024\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate execution time and resource usage\n",
    "        execution_time = end_time - start_time\n",
    "        cpu_time = end_cpu_time - start_cpu_time\n",
    "        memory_usage = end_memory_usage - start_memory_usage\n",
    "\n",
    "        num_cities = len(best_tour)\n",
    "\n",
    "        if perf_iterations > 1:\n",
    "            writer.writerow([i, execution_time * 1000, cpu_time * 1000, memory_usage, num_cities, num_cities ** 2, best_distance, best_tour])\n",
    "\n",
    "    # Calcul et affichage des résultats\n",
    "    calculate_results(best_tour)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Code avec paramètres pour lancer le recuit\n",
    "# Paramètres de contrôle\n",
    "temp_init = 10000\n",
    "cooling = 0.995\n",
    "temp_min = 0.0001\n",
    "nb_trucks = 1\n",
    "reheat_threshold = 0.001\n",
    "reheat_value = 300\n",
    "max_reheat_count = 6\n",
    "perf_iterations=1\n",
    "\n",
    "# Chemin du fichier contenant la matrice de coûts\n",
    "cost_matrix_file_path = 'vendor/Coords/matrix.txt'\n",
    "\n",
    "running(temp_init, cooling, temp_min, nb_trucks, reheat_threshold, reheat_value, max_reheat_count, perf_iterations)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Statistiques\n",
    "<img src=\"vendor/img/distance_vs_temps_execution.png\">\n",
    "<img src=\"vendor/img/cout_vs_noeuds.png\">\n",
    "<img src=\"vendor/img/temps_execution_vs_iterations.png\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
